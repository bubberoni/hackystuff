{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "flags = tf.app.flags\n",
    "logging = tf.logging\n",
    "\n",
    "flags.DEFINE_string(\"model\", \"small\", \"A type of model. Possible options are: small, medium, large.\")\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string(\"data_path\", '/home/ubuntu/simple-examples/data',\"Where the training/test data is stored.\")\n",
    "flags.DEFINE_string(\"save_path\", '/home/ubuntu/simple-examples/data/lang_model.ckpt',\n",
    "                    \"Model output directory.\")\n",
    "flags.DEFINE_bool(\"use_fp16\", False,\n",
    "                  \"Train using 16-bit floats instead of 32bit floats\")\n",
    "flags.DEFINE_integer(\"num_gpus\", 0,\n",
    "                     \"If larger than 1, Grappler AutoParallel optimizer \"\n",
    "                     \"will create multiple training replicas with each GPU \"\n",
    "                     \"running one replica.\")\n",
    "flags.DEFINE_string(\"rnn_mode\", None,\n",
    "                    \"The low level implementation of lstm cell: one of CUDNN, \"\n",
    "                    \"BASIC, and BLOCK, representing cudnn_lstm, basic_lstm, \"\n",
    "                    \"and lstm_block_cell classes.\")\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "BASIC = \"basic\"\n",
    "CUDNN = \"cudnn\"\n",
    "BLOCK = \"block\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utilities for parsing PTB text files.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "Py3 = sys.version_info[0] == 3\n",
    "\n",
    "def _read_words(filename):\n",
    "    with tf.gfile.GFile(filename, \"r\") as f:\n",
    "        if Py3:\n",
    "            return f.read().replace(\"\\n\", \"<eos>\").split()\n",
    "        else:\n",
    "            return f.read().decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()\n",
    "\n",
    "\n",
    "def _build_vocab(filename):\n",
    "    data = _read_words(filename)\n",
    "\n",
    "    counter = collections.Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "\n",
    "    # jwm: write out the vocabulary\n",
    "    with open('/home/ubuntu/temp/vocab.txt', 'w') as f:\n",
    "        for w in words:\n",
    "            f.write(w + '\\n')\n",
    "\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "\n",
    "    return word_to_id\n",
    "\n",
    "def _file_to_word_ids(filename, word_to_id):\n",
    "    data = _read_words(filename)\n",
    "    return [word_to_id[word] for word in data if word in word_to_id]\n",
    "\n",
    "\n",
    "def ptb_raw_data(data_path=None):\n",
    "    \"\"\"Load PTB raw data from data directory \"data_path\".\n",
    "    Reads PTB text files, converts strings to integer ids,\n",
    "    and performs mini-batching of the inputs.\n",
    "    The PTB dataset comes from Tomas Mikolov's webpage:\n",
    "    http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
    "    Args:\n",
    "        data_path: string path to the directory where simple-examples.tgz has\n",
    "            been extracted.\n",
    "    Returns:\n",
    "        tuple (train_data, valid_data, test_data, vocabulary)\n",
    "        where each of the data objects can be passed to PTBIterator.\n",
    "    \"\"\"\n",
    "\n",
    "    train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
    "    valid_path = os.path.join(data_path, \"ptb.valid.txt\")\n",
    "    test_path = os.path.join(data_path, \"ptb.test.txt\")\n",
    "\n",
    "    word_to_id = _build_vocab(train_path)\n",
    "    train_data = _file_to_word_ids(train_path, word_to_id)\n",
    "    valid_data = _file_to_word_ids(valid_path, word_to_id)\n",
    "    test_data = _file_to_word_ids(test_path, word_to_id)\n",
    "    vocabulary = len(word_to_id)\n",
    "    return train_data, valid_data, test_data, vocabulary\n",
    "\n",
    "\n",
    "def ptb_producer(raw_data, batch_size, num_steps, name=None):\n",
    "    \"\"\"Iterate on the raw PTB data.\n",
    "    This chunks up raw_data into batches of examples and returns Tensors that\n",
    "    are drawn from these batches.\n",
    "    Args:\n",
    "        raw_data: one of the raw data outputs from ptb_raw_data.\n",
    "        batch_size: int, the batch size.\n",
    "        num_steps: int, the number of unrolls.\n",
    "        name: the name of this operation (optional).\n",
    "    Returns:\n",
    "        A pair of Tensors, each shaped [batch_size, num_steps]. The second element\n",
    "        of the tuple is the same data time-shifted to the right by one.\n",
    "    Raises:\n",
    "        tf.errors.InvalidArgumentError: if batch_size or num_steps are too high.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, \"PTBProducer\", [raw_data, batch_size, num_steps]):\n",
    "        raw_data = tf.convert_to_tensor(raw_data, name=\"raw_data\", dtype=tf.int32)\n",
    "        print(raw_data) # \n",
    "        data_len = tf.size(raw_data)\n",
    "        print(data_len)\n",
    "        # jwm: num_batches would be a better name\n",
    "        batch_len = data_len // batch_size\n",
    "        print(batch_len)\n",
    "        # jwm: data of form [batch_size x num_batches]\n",
    "        data = tf.reshape(raw_data[0 : batch_size * batch_len],\n",
    "                                            [batch_size, batch_len])\n",
    "        print(\"Data form num_batches * batch_size\", data)\n",
    "        epoch_size = (batch_len - 1) // num_steps\n",
    "        print(epoch_size)\n",
    "        assertion = tf.assert_positive(\n",
    "                epoch_size,\n",
    "                message=\"epoch_size == 0, decrease batch_size or num_steps\")\n",
    "        with tf.control_dependencies([assertion]):\n",
    "            epoch_size = tf.identity(epoch_size, name=\"epoch_size\")\n",
    "\n",
    "        # jwm: You get some number between 0 and num_batches\n",
    "        i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()\n",
    "        x = tf.strided_slice(data, [0, i * num_steps],\n",
    "                                                 [batch_size, (i + 1) * num_steps])\n",
    "        x.set_shape([batch_size, num_steps])\n",
    "        y = tf.strided_slice(data, [0, i * num_steps + 1],\n",
    "                                                 [batch_size, (i + 1) * num_steps + 1])\n",
    "        y.set_shape([batch_size, num_steps])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/simple-examples/data\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/home/ubuntu/simple-examples/data/ptb.train.txt; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3eb8f6f2ef64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptb_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-67c8737e4cae>\u001b[0m in \u001b[0;36mptb_raw_data\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ptb.test.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mword_to_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_file_to_word_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_file_to_word_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-67c8737e4cae>\u001b[0m in \u001b[0;36m_build_vocab\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_build_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-67c8737e4cae>\u001b[0m in \u001b[0;36m_read_words\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPy3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<eos>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<eos>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/envs/venv/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/envs/venv/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self._read_buf = pywrap_tensorflow.CreateBufferedInputStream(\n\u001b[0;32m---> 80\u001b[0;31m             compat.as_bytes(self.__name), 1024 * 512, status)\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/envs/venv/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /home/ubuntu/simple-examples/data/ptb.train.txt; No such file or directory"
     ]
    }
   ],
   "source": [
    "\n",
    "print(FLAGS.data_path)\n",
    "raw_data = ptb_raw_data(FLAGS.data_path)\n",
    "train_data, valid_data, test_data, _ = raw_data\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "batch_size = 20\n",
    "num_steps = 20\n",
    "init_scale = 0.1\n",
    "epoch_size = ((len(train_data) // batch_size) - 1) // num_steps\n",
    "input_data, targets = ptb_producer(\n",
    "        train_data, batch_size, num_steps, name=\"name\")\n",
    "input_data\n",
    "print(tf.shape(input_data))\n",
    "#input to RNN newtowk is a seq of binary number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTBInput(object):\n",
    "    def __init__(self, config, data, name=None):\n",
    "        self.batch_size = batch_size = config.batch_size\n",
    "        self.num_steps = num_steps = config.num_steps\n",
    "        self.epoch_size = ((len(data) // batch_size) - 1) // num_steps\n",
    "        self.input_data, self.targets = ptb_producer(\n",
    "            data, batch_size, num_steps, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallConfig(object):\n",
    "    init_scale = 0.1\n",
    "    learning_rate = 1.0\n",
    "    max_grad_norm = 5\n",
    "    num_layers = 2\n",
    "    num_steps = 20\n",
    "    hidden_size = 20\n",
    "    max_epoch = 4\n",
    "    max_max_epoch = 13\n",
    "    keep_prob = 1.0\n",
    "    lr_decay = 0.5\n",
    "    batch_size = 20\n",
    "    vocab_size = 10000\n",
    "    embedding_size = 128\n",
    "    rnn_mode = BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    config = None\n",
    "    if FLAGS.model == \"small\":\n",
    "        config = SmallConfig()\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    initializer = tf.random_uniform_initializer(-init_scale,init_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "print(config)\n",
    "with tf.name_scope(\"Train\"):\n",
    "    train_input = PTBInput(config=config, data=train_data, name=\"TrainInput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PTB Model\n",
    "_is_training = True\n",
    "_input = train_input\n",
    "_rnn_params = None\n",
    "_cell = None\n",
    "batch_size = 20 #input batch size\n",
    "num_steps = 20  #input num_steps\n",
    "size = config.hidden_size\n",
    "vocab_size = config.vocab_size\n",
    "embedding_size = config.embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_type():\n",
    "    return tf.float16 if FLAGS.use_fp16 else tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='/home/ubuntu/rnn_lm.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    embedding = tf.get_variable(\"embeddingssssssssssSss\", [vocab_size, embedding_size], dtype=data_type())\n",
    "    inputs = tf.nn.embedding_lookup(embedding, train_data)\n",
    "embedding_size\n",
    "embedding.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization\n",
    "\n",
    "if _is_training and config.keep_prob < 1:\n",
    "    inputs = tf.nn.dropout(inputs, config.keep_prob)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.rnn_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if config.rnn_mode == BASIC:\n",
    "    tf.contrib.rnn.BasicLSTMCell(\n",
    "          config.hidden_size, forget_bias=0.0, state_is_tuple=True,\n",
    "          reuse=not True)\n",
    "elif config.rnn_mode == BLOCK:\n",
    "    tf.contrib.rnn.LSTMBlockCell(\n",
    "          config.hidden_size, forget_bias=0.0)\n",
    "else:\n",
    "    raise ValueError(\"rnn_mode %s not supported\" % config.rnn_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_rnn_graph_lstm(self, inputs, config):\n",
    "        \"\"\"Build the inference graph using canonical LSTM cells.\"\"\"\n",
    "        # Slightly better results can be obtained with forget gate biases\n",
    "        # initialized to 1 but the hyperparameters of the model would need to be\n",
    "        # different than reported in the paper.\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(config.hidden_size, forget_bias=0.0, state_is_tuple=True,reuse=not True)\n",
    "        if True and config.keep_prob < 1:\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(\n",
    "              cell, output_keep_prob=config.keep_prob)\n",
    "\n",
    "        cell = tf.contrib.rnn.MultiRNNCell(\n",
    "            [cell for _ in range(config.num_layers)], state_is_tuple=True)\n",
    "\n",
    "        self._initial_state = cell.zero_state(config.batch_size, data_type())\n",
    "        state = self._initial_state\n",
    "        # Simplified version of tensorflow_models/tutorials/rnn/rnn.py's rnn().\n",
    "        # This builds an unrolled LSTM for tutorial purposes only.\n",
    "        # In general, use the rnn() or state_saving_rnn() from rnn.py.\n",
    "        #\n",
    "        # The alternative version of the code below is:\n",
    "        #\n",
    "        # inputs = tf.unstack(inputs, num=num_steps, axis=1)\n",
    "        # outputs, state = tf.contrib.rnn.static_rnn(cell, inputs,\n",
    "        #                            initial_state=self._initial_state)\n",
    "        outputs = []\n",
    "        with tf.variable_scope(\"RNN\"):\n",
    "            for time_step in range(self.num_steps):\n",
    "                if time_step > 0: \n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "            (cell_output, state) = cell(inputs[:, time_step, :], state)\n",
    "            outputs.append(cell_output)\n",
    "            output = tf.reshape(tf.concat(outputs, 1), [-1, config.hidden_size])\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTBModel(object):\n",
    "    \"\"\"The PTB model.\"\"\"\n",
    "    def __init__(self, is_training, config, input_):\n",
    "        self._is_training = is_training\n",
    "        self._input = input_\n",
    "        self._rnn_params = None\n",
    "        self._cell = None\n",
    "        self.batch_size = input_.batch_size\n",
    "        self.num_steps = input_.num_steps\n",
    "        size = config.hidden_size\n",
    "        vocab_size = config.vocab_size\n",
    "\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            embedding = tf.get_variable(\n",
    "              \"embeddingssss\", [vocab_size, size], dtype=data_type())\n",
    "            inputs = tf.nn.embedding_lookup(embedding, input_.input_data)\n",
    "\n",
    "        if is_training and config.keep_prob < 1:\n",
    "            inputs = tf.nn.dropout(inputs, config.keep_prob)\n",
    "        output, state = self._build_rnn_graph(inputs, config, is_training)\n",
    "        print(\"Output is:\",output)\n",
    "        \n",
    "        softmax_w = tf.get_variable(\"softmax_w\", [size, vocab_size], dtype=data_type())\n",
    "        softmax_b = tf.get_variable(\"softmax_b\", [vocab_size], dtype=data_type())\n",
    "        \n",
    "        print(\"Softmax w:\", softmax_w)\n",
    "        print(\"Softmax b:\", softmax_b)\n",
    "        \n",
    "        logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "        print(logits)\n",
    "        logits = tf.reshape(logits, [self.batch_size, self.num_steps, vocab_size])\n",
    "        print(logits)\n",
    "\n",
    "        \n",
    "        # Use the contrib sequence loss and average over the batches\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(\n",
    "            logits,\n",
    "            input_.targets,\n",
    "            tf.ones([self.batch_size, self.num_steps], dtype=data_type()),\n",
    "            average_across_timesteps=False,\n",
    "            average_across_batch=True)\n",
    "        print(loss)\n",
    "\n",
    "    def _build_rnn_graph(self, inputs, config, is_training):\n",
    "        if config.rnn_mode == CUDNN:\n",
    "              return self._build_rnn_graph_cudnn(inputs, config, is_training)\n",
    "        else:\n",
    "              return self._build_rnn_graph_lstm(inputs, config, is_training)\n",
    "            \n",
    "    def _get_lstm_cell(self, config, is_training):\n",
    "        if config.rnn_mode == BASIC:\n",
    "            return tf.contrib.rnn.BasicLSTMCell(\n",
    "              config.hidden_size, forget_bias=0.0, state_is_tuple=True,\n",
    "              reuse=not is_training)\n",
    "        if config.rnn_mode == BLOCK:\n",
    "            return tf.contrib.rnn.LSTMBlockCell(\n",
    "              config.hidden_size, forget_bias=0.0)\n",
    "        raise ValueError(\"rnn_mode %s not supported\" % config.rnn_mode)\n",
    "\n",
    "    def _build_rnn_graph_lstm(self, inputs, config, is_training):\n",
    "        \"\"\"Build the inference graph using canonical LSTM cells.\"\"\"\n",
    "        # Slightly better results can be obtained with forget gate biases\n",
    "        # initialized to 1 but the hyperparameters of the model would need to be\n",
    "        # different than reported in the paper.\n",
    "        cell = self._get_lstm_cell(config, is_training)\n",
    "        if is_training and config.keep_prob < 1:\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(\n",
    "              cell, output_keep_prob=config.keep_prob)\n",
    "\n",
    "        cell = tf.contrib.rnn.MultiRNNCell(\n",
    "            [cell for _ in range(config.num_layers)], state_is_tuple=True)\n",
    "\n",
    "        self._initial_state = cell.zero_state(config.batch_size, data_type())\n",
    "        state = self._initial_state\n",
    "        # Simplified version of tensorflow_models/tutorials/rnn/rnn.py's rnn().\n",
    "        # This builds an unrolled LSTM for tutorial purposes only.\n",
    "        # In general, use the rnn() or state_saving_rnn() from rnn.py.\n",
    "        #\n",
    "        # The alternative version of the code below is:\n",
    "        #\n",
    "        # inputs = tf.unstack(inputs, num=num_steps, axis=1)\n",
    "        # outputs, state = tf.contrib.rnn.static_rnn(cell, inputs,\n",
    "        #                            initial_state=self._initial_state)\n",
    "        outputs = []\n",
    "        with tf.variable_scope(\"RNN\"):\n",
    "            for time_step in range(self.num_steps):\n",
    "                if time_step > 0: \n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "        (cell_output, state) = cell(inputs[:, time_step, :], state)\n",
    "        outputs.append(cell_output)\n",
    "        output = tf.reshape(tf.concat(outputs, 1), [-1, config.hidden_size])\n",
    "        return output, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Train\"):\n",
    "    train_input = PTBInput(config=config, data=train_data, name=\"TrainInput\")\n",
    "    with tf.variable_scope(\"Model\", reuse=tf.AUTO_REUSE, initializer=initializer):\n",
    "        m = PTBModel(is_training=True, config=config, input_=train_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='/home/ubuntu/softmax.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
